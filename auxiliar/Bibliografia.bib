@article{Blake1988,
author = {Blake, Barry B.},
doi = {10.1017/s0022226700011646},
file = {:C$\backslash$:/Users/hugo-/OneDrive/Documentos/Profesional/MATERIAL BIBLIOGRAFICO/Estad{\'{i}}stica/Natural Language Processing/Basic word order, Blake review.pdf:pdf},
issn = {0022-2267},
journal = {Journal of Linguistics},
number = {1},
pages = {213--217},
title = {{Russell S. Tomlin, Basic word order. Functional principles. London: Croom Helm, 1986. Pp. 308.}},
volume = {24},
year = {1988}
}
@article{Camacho2013,
abstract = {Purpose: Three cases of histopathologically confirmed central neurocytoma (CN) are presented, emphasizing diagnostic imaging issues: conventional magnetic resonance imaging with Proton magnetic resonance spectroscopy (MRS) and diffusion-weighted imaging (DWI) findings of CN. Materials and methods: Patients age ranged from 17 to 32 years, Imaging include a CT scan and MR examination with DWI and proton MRS on a 1.5-T system. DWI and subsequent apparent diffusion coefficient (ADC) were obtained in all. Single voxel MRS was performed prior to surgery using a point resolved spectroscopy sequence (PRESS) with short 35 ms and long echotime (TE) 144 ms, associated with a two-dimensional chemical Shift Imaging (2D-CSI) with 144 ms TE (one case). Histopathological examination included immunostaining with synaptophysin. Results: With the long TE, a variable amount of glycine with markedly increased choline, very small to almost complete loss of N-acetylaspartate and creatine, and inverted triplet of alaninelactate were observed in all three patients. Increased glutamate and glutamine complex (Glx) was also observed in all with short TE. DWI demonstrated variable low ADC which appeared well correlated with the tumor signal intensity and cell density: the most homogeneous and highly dense cellular tumor with increased nucleus to cytoplasm ratio demonstrated the lower ADC. Histological pattern was typical in two cases and demonstrated an oligodendroglioma-likepattern in one case. Positivity for synaptophysin confirmed the neuronal origin in all. Conclusion: The demonstration within an intraventricular tumor of both glycine and alanine onMRS along with high choline, bulky Glx and restricted diffusion appear diagnostic of CN. {\textcopyright} 2013 Published by Elsevier Masson SAS.},
author = {Camacho, John and Moreno, Socorro and Suarez-Obando, Fernando and Puyana, Juan Carlos and G{\'{o}}mez-Restrepo, Carlos},
file = {:C$\backslash$:/Users/hugo-/OneDrive/Documentos/Profesional/MATERIAL BIBLIOGRAFICO/Estad{\'{i}}stica/Natural Language Processing/NLP en Psiquiatr{\'{i}}a, Camacho.pdf:pdf},
journal = {Revista Colombiana de Psiquiatr{\'{i}}a},
keywords = {Depresi{\'{o}}n,ansiedad,estr{\'{e}}s,estudiantes de odonto},
number = {2},
pages = {173--181},
title = {{El procesamiento del lenguaje natural y su relaci{\'{o}}n con la investigaci{\'{o}}n en la salud mental}},
volume = {42},
year = {2013}
}
@misc{Abhishek2020,
author = {Abhishek, Sharma},
booktitle = {Analytics Vidhya},
title = {{Top 10 Applications of Natural Language Processing (NLP)}},
url = {https://www.analyticsvidhya.com/blog/2020/07/top-10-applications-of-natural-language-processing-nlp/},
year = {2020}
}

@book{Villalonga2019,
author = {Villalonga, Claudia},
publisher = {Universidad Internacional de la Rioja},
title = {{Procesamiento del Lenguaje Natural}},
year = {2019}
}
@book{Russell2005,
author = {Russell, Stuart and Norvig, Peter},
booktitle = {Learning},
file = {:C$\backslash$:/Users/hugo-/OneDrive/Documentos/Profesional/MATERIAL BIBLIOGRAFICO/Estad{\'{i}}stica/Artificial Intelligence/Artificial Intelligence A Modern Approach - Russell, Norvig.pdf:pdf},
isbn = {9781292153964},
keywords = {icle},
number = {3},
pages = {4},
title = {{AI a modern approach}},
volume = {2},
year = {2005}
}
@book{Sarkar2019,
author = {Sarkar, Dipanjan},
booktitle = {Text Analytics with Python},
doi = {10.1007/978-1-4842-4354-1},
file = {:C$\backslash$:/Users/hugo-/OneDrive/Documentos/Profesional/MATERIAL BIBLIOGRAFICO/Estad{\'{i}}stica/Natural Language Processing/Text Analytics with Python - Sarkar.pdf:pdf},
isbn = {9781484223871},
title = {{Text Analytics with Python}},
year = {2019}
}
@book{Silge2017,
author = {Silge, Julia and Robinson, David},
file = {:C$\backslash$:/Users/hugo-/OneDrive/Documentos/Profesional/MATERIAL BIBLIOGRAFICO/Estad{\'{i}}stica/Natural Language Processing/Text Mining with R{\_} A Tidy Approach - Julia Silge, David Robinson.pdf:pdf},
isbn = {978-1-491-98165-8},
title = {{Text Mining with R, a tidy approach}},
url = {http://oreilly.com/catalog/errata.csp?isbn=9781491981658},
year = {2017}
}
@book{Kwartler2017,
abstract = {A reliable, cost-effective approach to extracting priceless business information from all sources of text Excavating actionable business insights from data is a complex undertaking, and that complexity is magnified by an order of magnitude when the focus is on documents and other text information. This book takes a practical, hands-on approach to teaching you a reliable, cost-effective approach to mining the vast, untold riches buried within all forms of text using R. Author Ted Kwartler clearly describes all of the tools needed to perform text mining and shows you how to use them to identify practical business applications to get your creative text mining efforts started right away. With the help of numerous real-world examples and case studies from industries ranging from healthcare to entertainment to telecommunications, he demonstrates how to execute an array of text mining processes and functions, including sentiment scoring, topic modelling, predictive modelling, extracting clickbait from headlines, and more. You ll learn how to: Identify actionable social media posts to improve customer service Use text mining in HR to identify candidate perceptions of an organisation, match job descriptions with resumes, and more Extract priceless information from virtually all digital and print sources, including the news media, social media sites, PDFs, and even JPEG and GIF image files Make text mining an integral component of marketing in order to identify brand evangelists, impact customer propensity modelling, and much more Most companies data mining efforts focus almost exclusively on numerical and categorical data, while text remains a largely untapped resource. Especially in a global marketplace where being first to identify and respond to customer needs and expectations imparts an unbeatable competitive advantage, text represents a source of immense potential value. Unfortunately, there is no reliable, cost-effective technology for extracting analytical insights from the huge and ever-growing volume of text available online and other digital sources, as well as from paper documents until now.},
author = {Kwartler, Ted},
booktitle = {Wiley},
doi = {10.1080/00949655.2019.1630887},
file = {:C$\backslash$:/Users/hugo-/OneDrive/Documentos/Profesional/MATERIAL BIBLIOGRAFICO/Estad{\'{i}}stica/Natural Language Processing/Text Mining in Practice with R - Ted Kwartler.pdf:pdf},
isbn = {9781119282013},
issn = {0094-9655},
pages = {1--2},
title = {{Text mining in practice with R}},
year = {2017}
}

@article{Wickham2014,
abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
author = {Wickham, Hadley},
doi = {10.18637/jss.v059.i10},
file = {:C$\backslash$:/Users/hugo-/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wickham - 2014 - Tidy data.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Data cleaning,Data tidying,R,Relational databases},
number = {10},
pages = {1--23},
title = {{Tidy data}},
volume = {59},
year = {2014}
}

@article{Lovecraft2007,
abstract = {Howard Phillips Lovecraft (1890-1937) fue un ave nocturna y un cazador de sue{\~{n}}os. Naci{\'{o}} en Providence (Nueva Inglaterra), donde vivi{\'{o}} la mayor parte de su corta vida, que dedic{\'{o}} a contemplar las estrellas, leer con avidez cuanto ca{\'{i}}a en sus manos y, sobre todo, escribir (poes{\'{i}}a, ensayo, relatos y una ingente correspondencia). Al refugiarse en su herm{\'{e}}tico mundo on{\'{i}}rico, Lovecraft se embarc{\'{o}} en un viaje sin retorno hacia una nueva dimensi{\'{o}}n: el miedo c{\'{o}}smico, el «terror de los espacios infinitos», que estremec{\'{i}}a a Pascal. Como Poe, Lovecraft abandona definitivamente las invenciones m{\'{a}}gicas o legendarias de los g{\'{o}}ticos: el castillo encantado, los fantasmas, vampiros y brujas, y las sustituye por una nueva mitolog{\'{i}}a fant{\'{a}}stica en la que ya no hay Dios ni Diablo, ni seres sobrenaturales, tan s{\'{o}}lo h{\'{i}}bridos semihumanos y seres extraterrestres o extradimensionales. Y el miedo se convirti{\'{o}} en horror c{\'{o}}smico. A trav{\'{e}}s del sue{\~{n}}o y el vuelo de la fantas{\'{i}}a H.P.L. compens{\'{o}} su escasa movilidad f{\'{i}}sica y viaj{\'{o}} m{\'{a}}s lejos que nadie. Este primer volumen de su narrativa completa abarca la producci{\'{o}}n literaria de H.P. Lovecraft entre 1905 y 1926. Influido desde sus comienzos por Edgar Allan Poe, en relatos como “La tumba”, “El extra{\~{n}}o” o “Aire fr{\'{i}}o”, entre 1917 y 1921 escribi{\'{o}} casi una veintena de relatos on{\'{i}}ricos inspirados en otro de sus grandes maestros: Lord Dunsany. Cuentos de este periodo son “Dagon”, “Polaris”, “La ciudad sin nombre” o “La b{\'{u}}squeda en sue{\~{n}}os de la ignota Kadath”. As{\'{i}} mismo, en esta primera etapa de su carrera vio la luz “La llamada de Cthulhu” (1926), pieza b{\'{a}}sica y fundacional de los Mitos de Cthulhu, subg{\'{e}}nero lovecraftiano que cuenta con ilustres precursores, como Arthur Machen o Algernon Blackwood, as{\'{i}} como numerosos continuadores, especialmente los escritores que integran el llamado «C{\'{i}}rculo de Lovecraft». Ed. Valdemar},
author = {Lovecraft, Howard Phillips},
file = {:C$\backslash$:/Users/hugo-/Downloads/Conferencias/AnalisisComportamientoRedesSocialesNLP/Caso2{\_}Literatura/Narrativa completa vol. 1 - H. P. Lovecraft.pdf:pdf},
isbn = {84-7702-529-0},
journal = {Valdemar G{\'{o}}tica},
pages = {827},
title = {{Narrativa completa}},
volume = {1},
year = {2007}
}
@article{Lovecraft2007a,
abstract = {La figura de C{\'{e}}sar Vallejo (Santiago de Chuco 1892 - Par{\'{i}}s, 1938) forma parte de ese centro irradiador de la historia de la literatura hispanoamericana, su trayectoria existencial y literaria, abrazada hacia dos mundos (Europa y Am{\'{e}}rica), cuestiona los cimientos del lenguaje y construye, desde su m{\'{a}}s profunda humanidad, una ideolog{\'{i}}a y una est{\'{e}}tica que llega hasta nuestros d{\'{i}}as como la voz m{\'{a}}s personal de Hispanoam{\'{e}}rica. El presente volumen recoge buena parte de esa trayectoria, referida a su obra narrativa, desde la perspectiva hist{\'{o}}rico-social que representa la literatura de sus primeros a{\~{n}}os Escalas melografiadas y Fabla salvaje hasta el indigenismo profundo de Hacia el reino de los Sciris y el cuestionamiento de la realidad social de El tungsteno. Todo ello constituye un ejemplar mosaico de la realidad hispanoamericana de principios de siglo, acerc{\'{a}}ndonos con su pluma a un universo que se encuentra en constante reelaboraci{\'{o}}n.},
author = {Lovecraft, Howard Phillips},
file = {:C$\backslash$:/Users/hugo-/Downloads/Conferencias/AnalisisComportamientoRedesSocialesNLP/Caso2{\_}Literatura/Narrativa completa vol. 2 - H. P. Lovecraft.pdf:pdf},
isbn = {8446028565},
journal = {Valdemar G{\'{o}}tica},
pages = {323--340},
title = {{Narrativa completa}},
url = {http://books.google.com/books?id=BIsREg9HLjAC{\&}pgis=1},
volume = {2},
year = {2007}
}
@article{Straka2017,
abstract = {We present an update to UDPipe 1.0 (Straka et al., 2016), a trainable pipeline which performs sentence segmentation, tokenization, POS tagging, lemmatization and dependency parsing. We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline can be trained easily using data in CoNLL-U format. For the purpose of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, the updated UDPipe 1.1 was used as one of the baseline systems, finishing as the 13th system of 33 participants. A further improved UDPipe 1.2 participated in the shared task, placing as the 8th best system, while achieving low running times and moderately sized models. The tool is available under open-source Mozilla Public Licence (MPL) and provides bindings for C++, Python (through ufal.udpipe PyPI package), Perl (through UFAL::UDPipe CPAN package), Java and C{\#}.},
author = {Straka, Milan and Strakov{\'{a}}, Jana},
doi = {10.18653/v1/k17-3009},
file = {:C$\backslash$:/Users/hugo-/OneDrive/Documentos/Profesional/MATERIAL BIBLIOGRAFICO/Estad{\'{i}}stica/Natural Language Processing/UDPipe - Straka.pdf:pdf},
isbn = {9781945626708},
journal = {CoNLL 2017 - SIGNLL Conference on Computational Natural Language Learning, Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
keywords = {()},
pages = {88--99},
title = {{Tokenizing, POS tagging, lemmatizing and parsing UD 2.0 with UDPipe}},
volume = {2},
year = {2017}
}
@article{Thushara2019,
abstract = {Growth in the number of research documents getting published is increasing. Finding a research document under interested domain by referring the whole paper has become a tedious task. Keywords, Keyphrases gives the summary of the text. Keywords and keyphrases help in understanding the information described in the research document. The domain of a research document can be determined based on the keywords and keyphrases extracted. Extracting keywords and keyphrases manually is a tedious task. Automatic keyphrase extraction techniques help in overcoming this challenging task. This paper is a comparative study of unsupervised keyphrase extraction algorithms without using corpus. It compares the performance of PositionRank which considers the position of the all words occurrences in the document with TextRank and RAKE (Rapid Automatic Keyword Extraction).},
author = {Thushara, M. G. and Mownika, Tadi and Mangamuru, Ritika},
doi = {10.1109/ICCMC.2019.8819630},
file = {:C$\backslash$:/Users/hugo-/OneDrive/Documentos/Profesional/MATERIAL BIBLIOGRAFICO/Estad{\'{i}}stica/Natural Language Processing/Paper{\_}Thushara{\_}Mownika{\_}Ritika.pdf:pdf},
isbn = {9781538678084},
journal = {Proceedings of the 3rd International Conference on Computing Methodologies and Communication, ICCMC 2019},
keywords = {Automatic keyphrase extraction,Relevant keywords,Unsupervised technique},
number = {March},
pages = {969--973},
title = {{A comparative study on different keyword extraction algorithms}},
year = {2019}
}
@article{DeMarneffe2014,
abstract = {Revisiting the now de facto standard Stanford dependency representation, we propose an improved taxonomy to capture grammatical relations across languages, including morphologically rich ones. We suggest a two-layered taxonomy: a set of broadly attested universal grammatical relations, to which language-specific relations can be added. We emphasize the lexicalist stance of the Stanford Dependencies, which leads to a particular, partially new treatment of compounding, prepositions, and morphology. We show how existing dependency schemes for several languages map onto the universal taxonomy proposed here and close with consideration of practical implications of dependency representation choices for NLP applications, in particular parsing.},
author = {{De Marneffe}, Marie Catherine and Dozat, Timothy and Silveira, Natalia and Haverinen, Katri and Ginter, Filip and Nivre, Joakim and Manning, Christopher D.},
isbn = {9782951740884},
journal = {Proceedings of the 9th International Conference on Language Resources and Evaluation, LREC 2014},
keywords = {Dependency grammar,Grammatical taxonomy,Stanford dependencies},
pages = {4585--4592},
title = {{Universal stanford dependencies: A cross-linguistic typology}},
year = {2014}
}

@book{Geron2019,
author = {G{\'{e}}ron, Aur{\'{e}}lien},
isbn = {9788578110796},
issn = {1098-6596},
number = {9},
pmid = {25246403},
title = {{Hands-on Machine Learning with Scikit-Learn}},
volume = {53},
year = {2019}
}
@article{bischl2016,
  author  = {Bernd Bischl and Michel Lang and Lars Kotthoff and Julia Schiffner and Jakob Richter and Erich Studerus and Giuseppe Casalicchio and Zachary M. Jones},
  title   = {mlr: Machine Learning in R},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {170},
  pages   = {1-5},
  url     = {http://jmlr.org/papers/v17/15-066.html}
}
@book{GironesRoig2017,
abstract = {1{\textordfeminine} ed. en lengua castellana.},
author = {{Giron{\'{e}}s Roig}, Jordi and {Casas Roma}, Jordi and {Minguill{\'{o}}n Alfonso}, Juli{\`{a}} and {Caihuelas Quiles}, Ramon},
isbn = {9788491169048},
pages = {274},
title = {{Miner{\'{i}}a de datos: modelos y algoritmos}},
year = {2017}
}
@book{Hastie2012,
address = {California},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
edition = {Second},
isbn = {9781479932115},
publisher = {Springer},
title = {{The Elements of Statistical Learning}},
year = {2012}
}
@book{mlr2021,
  title = {mlr3 book},
  author = {Becker, Marc and Binder, Martin and Bischl, Bernd and Lang, Michel and Pfisterer, Florian and Reich, Nicholas and Richter, Jakob and Schratz, Patrick and Sonabend, Raphael},
  url = {https://mlr3book.mlr-org.com},
  year = {2021}
}

@article{Rajkumar2010,
  author  = {Arun, Rajkumar and Suresh, V. and Madhavan, C. E. Veni and Murthy, M. N. Narasimha },
  title   = {On finding the natural number of topics with latent dirichlet allocation: Some observations},
  journal = {Advances in knowledge discovery and data mining},
  year    = {2010},
  pages   = {391-402},
  url     = { http://doi.org/10.1007/978-3-642-13657-3_43}
}

@article{Juan2009,
  author  = {Juan, Cao and Tian, Xia and Jintao, Li and Yongdong, Zhang and Sheng, Tang},
  title   = {A density-based method for adaptive lda model selection},
  journal = {Neurocomputing},
  year    = {2009},
  pages   = {7-9},
  url     = {  http://doi.org/10.1016/j.neucom.2008.06.011}
}

@article{Deveaud2014,
  author  = {Deveaud, Romain and SanJuan, Éric and Bellot, Patrice},
  title   = {Accurate and effective latent concept modeling for ad hoc information retrieval},
  year    = {2014},
  pages   = {61-84},
  url     = {http://doi.org/10.3166/dn.17.1.61-84}
}

@article{Griffiths2004,
  author  = {Griffiths, Thomas L. and Steyvers, Mark},
  title   = { Finding scientific topics},
  journal = {Proceedings of the National Academy of Sciences},
  year    = {2004},
  pages   = {5228–5235},
  url     = {http://doi.org/10.1073/pnas.0307752101}
}

@book{Chollet2018,
author = {Chollet, Fran{\c{c}}ois and Allaire, Joseph},
booktitle = {Manning},
doi = {10.1111/biom.13224},
isbn = {9781617295546},
title = {{Deep learning with R}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13224},
year = {2018}
}

@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@book{Norvig2019,
author = {Norvig, Stuart and Russell, Peter},
booktitle = {Journal of Chemical Information and Modeling},
file = {:D$\backslash$:/OneDrive/Documentos/UNIR/TRABAJO FIN DE MASTER/Literatura/2020{\_}Russell{\_}Norvig.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Artificial Intelligence A Modern Approach}},
volume = {53},
year = {2019}
}



